# 第1章 行为——智能移动

1.1　简介 1

1.2　创建行为模板 2

1.3　追赶和逃跑 4

1.4　为物理引擎调整agent 6

1.5　到达和离开 8

1.6　朝向物体 10

1.7　徘徊 12

1.8　按路径移动 14

1.9　避开agent 18

1.10　避开墙体 20

1.11　通过权重混合多个行为 21

1.12　通过优先级混合多个行为 22

1.13　射击抛射体 24

1.14　预测抛射体的着地点 26

1.15　锁定抛射体 27

1.16　创建跳跃系统 28

# 第2章 导航

2.1　简介 32

2.2　用网格表示世界 33

2.3　用可视点法表示世界 41

2.4　用自制的导航网格表示世界 44

2.5　用深度优先搜索在迷宫中找到出路 47

2.6　用广度优先搜索在网格中找到最短路径 49

2.7　用迪杰斯特拉算法找到最短路径 50

2.8　用A*找到最优路径 53

2.9　改进A*算法的内存占用：IDA* 56

2.10　在多个帧中规划导航：时间片搜索 58

2.11　使路径变得平滑 60

# 第3章 决策制定

3.1　简介 62

3.2　通过决策树做选择 62

3.3　实现有限状态机 65

3.4　改进有限状态机：分层的有限状态机 67

3.5　实现行为树 69

3.6　使用模糊逻辑 71

3.7　用面向目标的行为制定决策 74

3.8　实现黑板架构 76

3.9　尝试Unity的动画状态机 78

# 第4章 新的NavMesh API

4.1　简介 84

4.2　初始化NavMesh开发组件 84

4.3　创建和管理NavMesh，用于多种类型的agent 86

4.4　在运行时创建和更新NavMesh数据 89

4.5　控制NavMesh实例的生命周期 90

4.6　连接多个NavMesh实例 92

4.7　创建动态的带有障碍物的NavMesh 93

4.8　用NavMesh API实现某些行为 94

# 第5章 协作和战术

5.1　简介 97

5.2　管理队形 98

5.3　扩展A*算法用于协作：A* mbush 102

5.4　用高度分析路径点 105

5.5　用覆盖性和可见性分析路径点 106

5.6　自动化创建路径点 107

5.7　将路径点作为示例用于决策制定 110

5.8　实现势力图 111

5.9　用淹没图改进势力图 114

5.10　用卷积滤波器改进势力图 118

5.11　构建战斗循环 120

# 第6章 agent感知

6.1　简介 128

6.2　基于碰撞系统的视觉函数 128

6.3　基于碰撞系统的听觉函数 130

6.4　基于碰撞系统的嗅觉函数 133

6.5　基于图的视觉函数 136

6.6　基于图的听觉函数 138

6.7　基于图的嗅觉函数 140

6.8　在潜行游戏中创建感知 141

# 第7章 棋类游戏和应用的搜索AI

7.1　简介 148

7.2　使用博弈树类 148

7.3　实现Minimax算法 150

7.4　实现Negamax算法 152

7.5　实现AB Negamax算法 154

7.6　实现Negascout算法 156

7.7　实现井字游戏对手 158

7.8　实现跳棋游戏对手 161

7.9　用UCB1实现石头剪刀布AI 171

7.10　实现无悔匹配算法 175

# 第8章 机器学习

8.1　简介 178

8.2　使用N元语法预测器预测行动 178

8.3　改进预测器：分层的N元语法 181

8.4　学习使用朴素贝叶斯分类器 182

8.5　实现强化学习 184

8.6　实现人工神经网络 188

# 第9章 程序化内容生成

9.1　简介 192

9.2　用深度优先搜索创建迷宫 192

9.3　为地下城和群岛实现可构造算法 195

9.4　生成风景 199

9.5　使用N元语法生成内容 201

9.6　用进化算法生成敌人 204

# 第10章 其他

10.1　简介 209

10.2　创建和管理可编写脚本的对象 209

10.3　更好地处理随机数 211

10.4　构建空气曲棍球游戏对手 213

10.5　实现竞速游戏架构 218

10.6　使用橡皮筋系统管理竞速难度 220